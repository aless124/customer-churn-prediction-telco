# ğŸ“Š Customer Churn Prediction - Telco Dataset

PrÃ©diction du churn client (rÃ©siliation de contrat) Ã  partir de donnÃ©es dâ€™une entreprise de tÃ©lÃ©communications. Ce projet met en Å“uvre un pipeline complet de machine learning : exploration, prÃ©paration des donnÃ©es, modÃ©lisation, interprÃ©tation, et recommandations business.

---

## ğŸ§  Objectif

Identifier les clients susceptibles de quitter lâ€™entreprise et comprendre les facteurs influents, afin dâ€™optimiser la rÃ©tention.

---

## ğŸ“ Structure du projet

```
customer-churn-prediction-telco/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # DonnÃ©es brutes
â”‚   â””â”€â”€ processed/                # DonnÃ©es nettoyÃ©es
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Exploration.ipynb      # Analyse exploratoire (EDA)
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb    # PrÃ©paration des donnÃ©es
â”‚   â”œâ”€â”€ 03_Modeling.ipynb         # EntraÃ®nement des modÃ¨les
â”‚   â”œâ”€â”€ 04_Evaluation.ipynb       # Ã‰valuation des modÃ¨les
â”‚   â””â”€â”€ 05_Interpretation.ipynb   # InterprÃ©tation avec SHAP
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py     # Fonctions de nettoyage
â”‚   â”œâ”€â”€ modeling.py               # Fonctions de modÃ©lisation
â”‚   â””â”€â”€ utils.py                  # Outils divers
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                  # Graphiques gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ models/                   # ModÃ¨les sauvegardÃ©s
â”‚
â”œâ”€â”€ requirements.txt              # DÃ©pendances
â”œâ”€â”€ churn_prediction.py           # Script principal (optionnel)
â”œâ”€â”€ README.md                     # Ce fichier
â””â”€â”€ .gitignore                    # Fichiers Ã  ignorer par Git

```

---

## ğŸ“¦ DonnÃ©es

- **Source** : [Telco Customer Churn Dataset (Kaggle)](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- **Contenu** : DonnÃ©es clients (contrats, services souscrits, donnÃ©es dÃ©mographiques, usage, paiement...)

---

## ğŸ› ï¸ MÃ©thodologie

1. **Exploration des donnÃ©es**
   - Analyse statistique
   - Visualisations (distribution des variables, corrÃ©lations)

2. **PrÃ©paration des donnÃ©es**
   - Traitement des valeurs manquantes
   - Encodage des variables catÃ©gorielles
   - Feature engineering

3. **ModÃ©lisation**
   - ModÃ¨les testÃ©s : Logistic Regression, Random Forest, XGBoost
   - Validation croisÃ©e, tuning dâ€™hyperparamÃ¨tres
   - Ã‰valuation : Accuracy, AUC, matrice de confusion

4. **InterprÃ©tation**
   - Importance des variables
   - Analyse SHAP pour interprÃ©tabilitÃ© locale et globale

5. **Recommandations**
   - StratÃ©gies de rÃ©tention pour les segments Ã  risque

---

## ğŸ“Š RÃ©sultats

- **ModÃ¨le retenu** : XGBoost
- **AUC** : 0.85
- **Principaux facteurs de churn** : contrat mensuel, absence d'engagement, montant Ã©levÃ© des charges mensuelles

---

## ğŸ§° Librairies utilisÃ©es

- `pandas`, `numpy`, `matplotlib`, `seaborn`
- `scikit-learn`
- `xgboost`
- `shap`
- `jupyter`

---

## ğŸš€ Lancer le projet

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sur Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer Jupyter
jupyter notebook